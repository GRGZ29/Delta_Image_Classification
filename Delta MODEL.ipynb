{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4ffa814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 885 images belonging to 5 classes.\n",
      "Found 100 images belonging to 5 classes.\n",
      "Epoch 1/30\n",
      "14/14 [==============================] - 72s 5s/step - loss: 1.4421 - accuracy: 0.3582 - val_loss: 1.2306 - val_accuracy: 0.4300\n",
      "Epoch 2/30\n",
      "14/14 [==============================] - 61s 4s/step - loss: 1.1908 - accuracy: 0.4927 - val_loss: 1.3187 - val_accuracy: 0.5000\n",
      "Epoch 3/30\n",
      "14/14 [==============================] - 61s 4s/step - loss: 1.2042 - accuracy: 0.4723 - val_loss: 1.2001 - val_accuracy: 0.4400\n",
      "Epoch 4/30\n",
      "14/14 [==============================] - 62s 4s/step - loss: 1.1030 - accuracy: 0.5232 - val_loss: 1.1483 - val_accuracy: 0.4900\n",
      "Epoch 5/30\n",
      "14/14 [==============================] - 65s 5s/step - loss: 1.0368 - accuracy: 0.5525 - val_loss: 1.1170 - val_accuracy: 0.5200\n",
      "Epoch 6/30\n",
      "14/14 [==============================] - 66s 5s/step - loss: 1.0444 - accuracy: 0.5356 - val_loss: 1.1000 - val_accuracy: 0.5600\n",
      "Epoch 7/30\n",
      "14/14 [==============================] - 64s 5s/step - loss: 1.0453 - accuracy: 0.5503 - val_loss: 1.1266 - val_accuracy: 0.5700\n",
      "Epoch 8/30\n",
      "14/14 [==============================] - 63s 4s/step - loss: 1.0243 - accuracy: 0.5763 - val_loss: 1.1364 - val_accuracy: 0.5300\n",
      "Epoch 9/30\n",
      "14/14 [==============================] - 66s 5s/step - loss: 0.9942 - accuracy: 0.5661 - val_loss: 1.0846 - val_accuracy: 0.5600\n",
      "Epoch 10/30\n",
      "14/14 [==============================] - 73s 5s/step - loss: 0.9916 - accuracy: 0.5808 - val_loss: 1.0634 - val_accuracy: 0.5600\n",
      "Epoch 11/30\n",
      "14/14 [==============================] - 66s 5s/step - loss: 0.9915 - accuracy: 0.5864 - val_loss: 1.1634 - val_accuracy: 0.5100\n",
      "Epoch 12/30\n",
      "14/14 [==============================] - 66s 5s/step - loss: 0.9810 - accuracy: 0.5774 - val_loss: 1.1026 - val_accuracy: 0.5100\n",
      "Epoch 13/30\n",
      "14/14 [==============================] - 72s 5s/step - loss: 0.9925 - accuracy: 0.5853 - val_loss: 1.1144 - val_accuracy: 0.5100\n",
      "Epoch 14/30\n",
      "14/14 [==============================] - 69s 5s/step - loss: 0.9613 - accuracy: 0.6056 - val_loss: 1.1081 - val_accuracy: 0.5500\n",
      "Epoch 15/30\n",
      "14/14 [==============================] - 82s 6s/step - loss: 0.9656 - accuracy: 0.5887 - val_loss: 1.0413 - val_accuracy: 0.5300\n",
      "Epoch 16/30\n",
      "14/14 [==============================] - 93s 7s/step - loss: 0.9327 - accuracy: 0.6192 - val_loss: 1.0422 - val_accuracy: 0.5400\n",
      "Epoch 17/30\n",
      "14/14 [==============================] - 79s 6s/step - loss: 0.9666 - accuracy: 0.5819 - val_loss: 1.0786 - val_accuracy: 0.5100\n",
      "Epoch 18/30\n",
      "14/14 [==============================] - 64s 4s/step - loss: 0.9175 - accuracy: 0.6079 - val_loss: 1.0556 - val_accuracy: 0.5200\n",
      "Epoch 19/30\n",
      "14/14 [==============================] - 63s 4s/step - loss: 0.9068 - accuracy: 0.6124 - val_loss: 1.1480 - val_accuracy: 0.4900\n",
      "Epoch 20/30\n",
      "14/14 [==============================] - 67s 5s/step - loss: 0.9195 - accuracy: 0.6158 - val_loss: 1.0193 - val_accuracy: 0.6000\n",
      "Epoch 21/30\n",
      "14/14 [==============================] - 72s 5s/step - loss: 0.9741 - accuracy: 0.6000 - val_loss: 1.1724 - val_accuracy: 0.4800\n",
      "Epoch 22/30\n",
      "14/14 [==============================] - 69s 5s/step - loss: 0.9422 - accuracy: 0.5887 - val_loss: 1.0428 - val_accuracy: 0.5400\n",
      "Epoch 23/30\n",
      "14/14 [==============================] - 75s 5s/step - loss: 0.9161 - accuracy: 0.5977 - val_loss: 1.1279 - val_accuracy: 0.5800\n",
      "Epoch 24/30\n",
      "14/14 [==============================] - 72s 5s/step - loss: 0.9366 - accuracy: 0.6090 - val_loss: 1.1369 - val_accuracy: 0.4900\n",
      "Epoch 25/30\n",
      "14/14 [==============================] - 65s 5s/step - loss: 0.8937 - accuracy: 0.6328 - val_loss: 1.0344 - val_accuracy: 0.5600\n",
      "Epoch 26/30\n",
      "14/14 [==============================] - 67s 5s/step - loss: 0.9102 - accuracy: 0.6215 - val_loss: 1.0115 - val_accuracy: 0.5700\n",
      "Epoch 27/30\n",
      "14/14 [==============================] - 64s 5s/step - loss: 0.8954 - accuracy: 0.6328 - val_loss: 1.0367 - val_accuracy: 0.5100\n",
      "Epoch 28/30\n",
      "14/14 [==============================] - 65s 5s/step - loss: 0.9010 - accuracy: 0.6226 - val_loss: 1.0566 - val_accuracy: 0.5300\n",
      "Epoch 29/30\n",
      "14/14 [==============================] - 63s 5s/step - loss: 0.8844 - accuracy: 0.6282 - val_loss: 1.0179 - val_accuracy: 0.5600\n",
      "Epoch 30/30\n",
      "14/14 [==============================] - 64s 5s/step - loss: 0.9148 - accuracy: 0.6305 - val_loss: 1.0207 - val_accuracy: 0.5200\n",
      "2/2 [==============================] - 6s 2s/step - loss: 1.0207 - accuracy: 0.5200\n",
      "Overall Accuracy: 52.00%\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from efficientnet.tfkeras import EfficientNetB0  # Change the import to EfficientNetB0\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load pre-trained EfficientNetB0 model without top (fully connected) layers\n",
    "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))  # Adjust input shape\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom top layers for the new task\n",
    "num_classes = 5\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)  # Adjust num_classes for your specific task\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=SGD(learning_rate=0.03, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fine-tune the model on a new dataset\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(r'C:\\Users\\RUBINOS\\Desktop\\Diabetic Retinopathy\\training', target_size=(224, 224), batch_size=64, class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(r'C:\\Users\\RUBINOS\\Desktop\\Diabetic Retinopathy\\testing', target_size=(224, 224), batch_size=64, class_mode='categorical')\n",
    "\n",
    "model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=30, validation_data=validation_generator, validation_steps=len(validation_generator))\n",
    "\n",
    "# Evaluate the model on the validation set\n",
    "evaluation = model.evaluate(validation_generator, steps=len(validation_generator))\n",
    "\n",
    "# Print the overall accuracy\n",
    "accuracy = evaluation[1] * 100\n",
    "print(f'Overall Accuracy: {accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662aa6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RUBINOS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as HDFS file.\n"
     ]
    }
   ],
   "source": [
    "model.save('C:/Users/RUBINOS/Desktop/Diabetic Retinopathy/Untitled12.h5')\n",
    "print(\"Model saved as HDFS file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26478d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
